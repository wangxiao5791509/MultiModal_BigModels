
* **An overview of multi-modal datasets proposed for large-scale pre-training.
and Available, respectively.** 

|**NO.**     | **Dataset**   | **Year**           | **Scale**           | **Modality**       | **Language**      |**Available**  |**URL**            |
|:-----------|:-----------   |:----------------   |:----------------    |:----------------   |:----------------  |:----------------|:----------------|
|01  | SBU Captions    |2011     |1M  |image-text |English     |Yes     	|[[Link](http://www.cs.virginia.edu/~vicente/sbucaptions/)]     	|  
|02  | Flickr30k   |2014     |145K     |image-text     	|English     |Yes     	|[[Link](http://nlp.cs.illinois.edu/)]     	|
|03  | COCO   |2014     |567K     |image-text     	|English     |Yes     	|[[Link](https://cocodataset.org/#home)]     	|         
|04  | Visual Genome     |2017     |5.4M     |image-text     	|English     |Yes     	|[[Link](https://visualgenome.org/)]    	|         
|05  | VQA v2.0    |2017     |1.1M     |image-text |English     |Yes     	|[[Link](https://visualqa.org/)]     	|  
|06  | FashionGen     |2018     |300k     |image-text     	|English     |Yes     	|[[Link](https://fashion-gen.com/)]     	|         
|07  | CC3M  |2018     |3M     |image-text     	|English     |Yes     	|[[Link](https://github.com/google-research-datasets/conceptual-captions)]     	|         
|08  | GQA       |2019     |1M     |image-text     |English     |Yes |[[Link](https://cs.stanford.edu/people/dorarad/gqa/)]     	|         
|09 | LAIT     |2020     |10M     |image-text     	|English   |No |-     	|       
|10  | CC12M     |2021     |12M     |image-text    |English  |Yes 	|[[Link](https://github.com/google-research-datasets/conceptual-12m)]    	|       
|11  | AltText   |2021     |1.8B     |image-text     |English  |No	|-     	|       
|12  | TVQA        |2018     |21,793     |video-text     |English     |Yes	|[[Link](http://tvqa.cs.unc.edu/)]     	|       
|13  | HT100M    |2019     |136M     |video-text     |English     |Yes	|[[Link](https://www.di.ens.fr/willow/research/howto100m)]     	|       
|14  | WebVid2M  |2021     |2.5M     |video-text     |English    	|Yes	|[[Link](https://github.com/m-bain/webvid)]     	|       
|15  | YFCC-100M |2015     |100M     |image-text     |English     |Yes	|[[Link](http://projects.dfki.uni-kl.de/yfcc100m/)] | 
|16  | LAION-400M   |2021     |400M     |image-text     |English     |Yes	|[[Link](https://laion.ai/laion-400-open-dataset/)] | 
|17  | RedCaps   |2021     |12M     |image-text     |English     |Yes	|[[Link](https://redcaps.xyz/)] |        
|18  | Wukong   |2022     |100M     |image-text |Chinese     |Yes	|[[Link](https://wukong-dataset.github.io/wukong-dataset/index.html)] |    
|19  | CxC |2021     |24K     |image-text |English     |Yes	|[[Link](https://github.com/google-research-datasets/Crisscrossed-Captions)] |   
|20  | Product1M |2021     |1M     |image-text |Chinese     |Yes	|[[Link](https://github.com/zhanxlin/Product1M)] |  
|21  | WIT |2021     |37.5M     |image-text |Multi-lingual     |Yes	|[[Link](https://github.com/google-research-datasets/wit)] | 
|22  | JFT-300M |2017     |30M     |image-text |English     |No	|- | 
|23  | JFT-3B |2021     |3000M     |image-text |English     |No	|- | 
|24  | IG-3.5B-17k |2018     |350M     |image-text |English     |No	|- | 
|25  | M6-Corpus |2021   |60M     |image, image-text |Chinese     |No	|- | 
|26  | M5Product  |2021     |6M     |image, text, table, video, audio |English     |Yes	|[[Link](https://xiaodongsuper.github.io/M5Product_dataset/index.html)] | 
|27  | Localized Narratives  |2020    |849k     |image, audio, text, mouse trace |English     |Yes	|[[Link](https://google.github.io/localized-narratives/)] |  
|28  | RUC-CAS-WenLan |2021     |30M     |image-text |Chinese     |No	|- | 
|29  | WuDaoMM |2022    |600M     |image-text |Chinese     |Yes	|[[Link](https://data.wudaoai.cn/home)] | 
|30  | MEP-3M |2021 |3M |image-text |Chinese     |Yes	|[[Link](https://github.com/ChenDelong1999/MEP-3M)] | 
|31  | WSCD |2021 |650M |image-text |Chinese |No	|- | 









